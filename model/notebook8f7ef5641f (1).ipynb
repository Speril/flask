{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3QKa08KPZYRe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18901,
     "status": "ok",
     "timestamp": 1623600881140,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "3QKa08KPZYRe",
    "outputId": "8ef6a30f-6d93-4035-cde6-a2ce1319d805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sublime-batch",
   "metadata": {
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1623600888396,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "sublime-batch"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, sys, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "img_dir = '/content/drive/MyDrive/Covid Model/CT'\n",
    "categories = ['COVID','Non-COVID']\n",
    "n_classes = len(categories)\n",
    "\n",
    "image_w = 112\n",
    "image_h = 112\n",
    "\n",
    "\n",
    "pixel = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# for idx, cat in enumerate(categories):\n",
    "#     img_dir_detail = img_dir + \"/\" + cat\n",
    "#     files = glob.glob(img_dir_detail+\"/*.png\")\n",
    "\n",
    "\n",
    "#     for i, f in enumerate(files):\n",
    "#         try:\n",
    "#             img = Image.open(f)\n",
    "#             img = img.convert(\"RGB\")\n",
    "#             img = img.resize((image_w, image_h))\n",
    "#             data = np.asarray(img)\n",
    "#             #Y는 0 아니면 1이니까 idx값으로 넣는다.\n",
    "#             X.append(data)\n",
    "#             y.append(idx)\n",
    "#             if i % 300 == 0:\n",
    "#                 print(cat, \" : \", f)\n",
    "#         except:\n",
    "#             print(cat, str(i)+\" 번째에서 에러 \")\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# xy = (X_train, X_test, y_train, y_test)\n",
    "# np.save(\"binary_image_data.npy\", xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "secret-patient",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6024,
     "status": "ok",
     "timestamp": 1623600897745,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "secret-patient",
    "outputId": "d0281f35-11b1-4095-a398-9db53a671011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11381, 112, 112, 3)\n",
      "11381\n",
      "[4801 6580]\n",
      "[545 720]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#np_load_old = np.load\n",
    "#np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "X_train, X_test, y_train, y_test = np.load('/content/drive/MyDrive/Covid Model/binary_image_data.npy', allow_pickle=True)\n",
    "#np.load = np_load_old\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunset-vintage",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 991,
     "status": "ok",
     "timestamp": 1623600905731,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "sunset-vintage",
    "outputId": "ef14facc-4bd3-433b-a3e7-ba042586fb6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11381, 112, 112, 3) (11381, 2) (1265, 112, 112, 3) (1265, 2)\n",
      "학습 데이터셋 크기: 11381\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 112\n",
    "BATCH_SIZE = 16\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "# print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "print('학습 데이터셋 크기:', len(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bridal-joseph",
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1623600910835,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "bridal-joseph"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import cv2\n",
    "import sklearn\n",
    "\n",
    "# 입력 인자 images_array labels는 모두 numpy array로 들어옴. \n",
    "# 인자로 입력되는 images_array는 전체 32x32 image array임. \n",
    "class _Dataset(Sequence):\n",
    "    def __init__(self, images_array, labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=None):\n",
    "        '''\n",
    "        파라미터 설명\n",
    "        images_array: 원본 32x32 만큼의 image 배열값. \n",
    "        labels: 해당 image의 label들\n",
    "        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n",
    "        augmentor: albumentations 객체\n",
    "        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n",
    "        '''\n",
    "        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n",
    "        # 인자로 입력되는 images_array는 전체 32x32 image array임.\n",
    "        self.images_array = images_array\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentor = augmentor\n",
    "        self.pre_func = pre_func\n",
    "        # train data의 경우 \n",
    "        self.shuffle = shuffle\n",
    "        if self.shuffle:\n",
    "            # 객체 생성시에 한번 데이터를 섞음. \n",
    "            #self.on_epoch_end()\n",
    "            pass\n",
    "    \n",
    "    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n",
    "    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n",
    "    def __len__(self):\n",
    "        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n",
    "        return int(np.ceil(len(self.labels) / self.batch_size))\n",
    "    \n",
    "    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n",
    "    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n",
    "    # batch_size 갯수만큼 변환된 image_array와 label_array 반환. \n",
    "    def __getitem__(self, index):\n",
    "        images_fetch = self.images_array[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        if self.labels is not None:\n",
    "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n",
    "        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n",
    "        # 변환된 image 배열값을 담을 image_batch 선언. image_batch 배열은 float32 로 설정. \n",
    "        image_batch = np.zeros((images_fetch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3), dtype='float32')\n",
    "        \n",
    "        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환(augmentor가 not None일 경우)-> image_batch에 담음. \n",
    "        for image_index in range(images_fetch.shape[0]):\n",
    "            #image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
    "            # 원본 image를 IMAGE_SIZE x IMAGE_SIZE 크기로 변환\n",
    "            image = cv2.resize(images_fetch[image_index], (IMAGE_SIZE, IMAGE_SIZE))\n",
    "            # 만약 augmentor가 주어졌다면 이를 적용. \n",
    "            if self.augmentor is not None:\n",
    "                image = self.augmentor(image=image)['image']\n",
    "                \n",
    "            # 만약 scaling 함수가 입력되었다면 이를 적용하여 scaling 수행. \n",
    "            if self.pre_func is not None:\n",
    "                image = self.pre_func(image)\n",
    "            \n",
    "            # image_batch에 순차적으로 변환된 image를 담음.               \n",
    "            image_batch[image_index] = image\n",
    "        \n",
    "        return image_batch, label_batch\n",
    "    \n",
    "    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n",
    "    def on_epoch_end(self):\n",
    "        if(self.shuffle):\n",
    "            #print('epoch end')\n",
    "            # 원본 image배열과 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n",
    "            self.images_array, self.labels = sklearn.utils.shuffle(self.images_array, self.labels)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "innovative-ultimate",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "error",
     "timestamp": 1623600914807,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "innovative-ultimate",
    "outputId": "92028fe4-9b02-48be-b5da-9781c1cedb7e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f915ef2c570e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# tr_ds = _Dataset(X_train, y_train, batch_size=BATCH_SIZE, augmentor=None, shuffle=True, pre_func=vgg_preprocess)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvgg_preprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg_preprocess\n",
    "\n",
    "# tr_ds = _Dataset(X_train, y_train, batch_size=BATCH_SIZE, augmentor=None, shuffle=True, pre_func=vgg_preprocess)\n",
    "val_ds = _Dataset(X_val, y_val, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=vgg_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-afternoon",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6243,
     "status": "ok",
     "timestamp": 1623219273721,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "irish-afternoon",
    "outputId": "7e4de987-8081-4295-c8af-f21e0dee994a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 0s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 20,158,274\n",
      "Trainable params: 20,157,250\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers \n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop , SGD\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "input_tensor = Input(shape=(112, 112, 3))\n",
    "base_model = VGG19(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers. GlobalAveragePooling2D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(n_classes, activation = 'softmax'))\n",
    "model.summary()\n",
    "# , kernel_regularizer=keras.regularizers.l2(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "integral-american",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "error",
     "timestamp": 1623600940958,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "integral-american",
    "outputId": "cc660903-e6c9-4af3-af21-230e753c559d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cb625e590978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.compile(optimizer=SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True), loss='binary_crossentropy', metrics=['accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"COVIDMD.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrlr_cb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# model.compile(optimizer=SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_path = \"COVIDMD.h5\"\n",
    "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
    "ely_cb = EarlyStopping(monitor='val_loss', patience=50, mode='min', verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, \n",
    "                                 save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-gallery",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3904433,
     "status": "ok",
     "timestamp": 1622907020833,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "posted-gallery",
    "outputId": "945df4f7-0178-425a-9624-7c14e1845af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "569/569 [==============================] - 82s 86ms/step - loss: 0.2656 - accuracy: 0.8742 - val_loss: 512.5906 - val_accuracy: 0.5841\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 512.59058, saving model to COVIDMD.h5\n",
      "Epoch 2/4000\n",
      "569/569 [==============================] - 49s 86ms/step - loss: 0.2082 - accuracy: 0.8955 - val_loss: 71.1768 - val_accuracy: 0.8805\n",
      "\n",
      "Epoch 00002: val_loss improved from 512.59058 to 71.17682, saving model to COVIDMD.h5\n",
      "Epoch 3/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.1986 - accuracy: 0.9027 - val_loss: 757286.8125 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 71.17682\n",
      "Epoch 4/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.1857 - accuracy: 0.9097 - val_loss: 0.1586 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00004: val_loss improved from 71.17682 to 0.15862, saving model to COVIDMD.h5\n",
      "Epoch 5/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.1770 - accuracy: 0.9196 - val_loss: 0.5160 - val_accuracy: 0.8287\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15862\n",
      "Epoch 6/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.1693 - accuracy: 0.9221 - val_loss: 6.4171 - val_accuracy: 0.4418\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15862\n",
      "Epoch 7/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.1533 - accuracy: 0.9306 - val_loss: 0.2548 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15862\n",
      "Epoch 8/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.1264 - accuracy: 0.9458 - val_loss: 0.1101 - val_accuracy: 0.9578\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.15862 to 0.11008, saving model to COVIDMD.h5\n",
      "Epoch 9/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.1162 - accuracy: 0.9543 - val_loss: 0.1647 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11008\n",
      "Epoch 10/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.1125 - accuracy: 0.9583 - val_loss: 5.2121 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.11008\n",
      "Epoch 11/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.1019 - accuracy: 0.9589 - val_loss: 0.1207 - val_accuracy: 0.9455\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.11008\n",
      "Epoch 12/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0909 - accuracy: 0.9677 - val_loss: 0.0861 - val_accuracy: 0.9666\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.11008 to 0.08607, saving model to COVIDMD.h5\n",
      "Epoch 13/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0864 - accuracy: 0.9677 - val_loss: 0.0850 - val_accuracy: 0.9675\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08607 to 0.08496, saving model to COVIDMD.h5\n",
      "Epoch 14/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0832 - accuracy: 0.9679 - val_loss: 0.0892 - val_accuracy: 0.9635\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.08496\n",
      "Epoch 15/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0836 - accuracy: 0.9673 - val_loss: 0.0898 - val_accuracy: 0.9666\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.08496\n",
      "Epoch 16/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0816 - accuracy: 0.9677 - val_loss: 0.0840 - val_accuracy: 0.9684\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08496 to 0.08396, saving model to COVIDMD.h5\n",
      "Epoch 17/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0815 - accuracy: 0.9706 - val_loss: 0.0821 - val_accuracy: 0.9688\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.08396 to 0.08207, saving model to COVIDMD.h5\n",
      "Epoch 18/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0772 - accuracy: 0.9705 - val_loss: 0.0814 - val_accuracy: 0.9693\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08207 to 0.08138, saving model to COVIDMD.h5\n",
      "Epoch 19/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0766 - accuracy: 0.9694 - val_loss: 0.0748 - val_accuracy: 0.9693\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.08138 to 0.07477, saving model to COVIDMD.h5\n",
      "Epoch 20/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0739 - accuracy: 0.9714 - val_loss: 0.0861 - val_accuracy: 0.9657\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07477\n",
      "Epoch 21/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0780 - accuracy: 0.9705 - val_loss: 0.0780 - val_accuracy: 0.9662\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.07477\n",
      "Epoch 22/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0727 - accuracy: 0.9713 - val_loss: 0.0729 - val_accuracy: 0.9715\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.07477 to 0.07292, saving model to COVIDMD.h5\n",
      "Epoch 23/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0731 - accuracy: 0.9735 - val_loss: 0.1694 - val_accuracy: 0.9675\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.07292\n",
      "Epoch 24/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0715 - accuracy: 0.9730 - val_loss: 0.0755 - val_accuracy: 0.9693\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07292\n",
      "Epoch 25/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0682 - accuracy: 0.9739 - val_loss: 0.0751 - val_accuracy: 0.9679\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.07292\n",
      "Epoch 26/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0650 - accuracy: 0.9747 - val_loss: 0.0709 - val_accuracy: 0.9688\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.07292 to 0.07087, saving model to COVIDMD.h5\n",
      "Epoch 27/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0667 - accuracy: 0.9736 - val_loss: 0.0722 - val_accuracy: 0.9693\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.07087\n",
      "Epoch 28/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0644 - accuracy: 0.9755 - val_loss: 0.0699 - val_accuracy: 0.9719\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.07087 to 0.06993, saving model to COVIDMD.h5\n",
      "Epoch 29/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0620 - accuracy: 0.9754 - val_loss: 0.0709 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06993\n",
      "Epoch 30/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0619 - accuracy: 0.9764 - val_loss: 0.0705 - val_accuracy: 0.9719\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06993\n",
      "Epoch 31/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0616 - accuracy: 0.9762 - val_loss: 0.0709 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.06993\n",
      "Epoch 32/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0611 - accuracy: 0.9765 - val_loss: 0.0706 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.06993\n",
      "Epoch 33/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0649 - accuracy: 0.9750 - val_loss: 0.0710 - val_accuracy: 0.9715\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.06993\n",
      "Epoch 34/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0624 - accuracy: 0.9765 - val_loss: 0.0704 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.06993\n",
      "Epoch 35/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0582 - accuracy: 0.9776 - val_loss: 0.0705 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.06993\n",
      "Epoch 36/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0593 - accuracy: 0.9768 - val_loss: 0.0724 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.06993\n",
      "Epoch 37/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0578 - accuracy: 0.9785 - val_loss: 0.0718 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.06993\n",
      "Epoch 38/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0605 - accuracy: 0.9767 - val_loss: 0.0707 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.06993\n",
      "Epoch 39/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0648 - accuracy: 0.9759 - val_loss: 0.0708 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.06993\n",
      "Epoch 40/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0584 - accuracy: 0.9776 - val_loss: 0.0712 - val_accuracy: 0.9715\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.06993\n",
      "Epoch 41/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0613 - accuracy: 0.9769 - val_loss: 0.0709 - val_accuracy: 0.9715\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.06993\n",
      "Epoch 42/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0599 - accuracy: 0.9773 - val_loss: 0.0729 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.06993\n",
      "Epoch 43/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0594 - accuracy: 0.9774 - val_loss: 0.0706 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.06993\n",
      "Epoch 44/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0619 - accuracy: 0.9775 - val_loss: 0.0720 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.06993\n",
      "Epoch 45/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0619 - accuracy: 0.9779 - val_loss: 0.0706 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.06993\n",
      "Epoch 46/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0594 - accuracy: 0.9773 - val_loss: 0.0705 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.06993\n",
      "Epoch 47/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0601 - accuracy: 0.9761 - val_loss: 0.0706 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.06993\n",
      "Epoch 48/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0594 - accuracy: 0.9765 - val_loss: 0.0705 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.06993\n",
      "Epoch 49/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0604 - accuracy: 0.9765 - val_loss: 0.0708 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.06993\n",
      "Epoch 50/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0617 - accuracy: 0.9763 - val_loss: 0.0707 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.06993\n",
      "Epoch 51/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0629 - accuracy: 0.9755 - val_loss: 0.0706 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.06993\n",
      "Epoch 52/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0598 - accuracy: 0.9764 - val_loss: 0.0703 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.0480002416167767e-11.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.06993\n",
      "Epoch 53/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0613 - accuracy: 0.9768 - val_loss: 0.0709 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.06993\n",
      "Epoch 54/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0602 - accuracy: 0.9774 - val_loss: 0.0710 - val_accuracy: 0.9715\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.06993\n",
      "Epoch 55/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0625 - accuracy: 0.9761 - val_loss: 0.0708 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 4.096000622011431e-12.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.06993\n",
      "Epoch 56/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0598 - accuracy: 0.9767 - val_loss: 0.0710 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.06993\n",
      "Epoch 57/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0608 - accuracy: 0.9779 - val_loss: 0.0721 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.06993\n",
      "Epoch 58/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0606 - accuracy: 0.9767 - val_loss: 0.0755 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 8.192000897078167e-13.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.06993\n",
      "Epoch 59/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0608 - accuracy: 0.9761 - val_loss: 0.0705 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.06993\n",
      "Epoch 60/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0592 - accuracy: 0.9752 - val_loss: 0.0707 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.06993\n",
      "Epoch 61/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0597 - accuracy: 0.9787 - val_loss: 0.0706 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.6384001360475466e-13.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.06993\n",
      "Epoch 62/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0630 - accuracy: 0.9772 - val_loss: 0.0711 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.06993\n",
      "Epoch 63/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0623 - accuracy: 0.9766 - val_loss: 0.0761 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.06993\n",
      "Epoch 64/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0596 - accuracy: 0.9768 - val_loss: 0.0705 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.2768002178849846e-14.\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.06993\n",
      "Epoch 65/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0596 - accuracy: 0.9769 - val_loss: 0.0708 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.06993\n",
      "Epoch 66/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0621 - accuracy: 0.9752 - val_loss: 0.0704 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.06993\n",
      "Epoch 67/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0616 - accuracy: 0.9747 - val_loss: 0.0708 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 6.553600300244697e-15.\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.06993\n",
      "Epoch 68/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0655 - accuracy: 0.9762 - val_loss: 0.0707 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.06993\n",
      "Epoch 69/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0598 - accuracy: 0.9770 - val_loss: 0.0708 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.06993\n",
      "Epoch 70/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0582 - accuracy: 0.9777 - val_loss: 0.0707 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.3107200431082805e-15.\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.06993\n",
      "Epoch 71/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 0.0706 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.06993\n",
      "Epoch 72/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0593 - accuracy: 0.9759 - val_loss: 0.0706 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06993\n",
      "Epoch 73/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0610 - accuracy: 0.9767 - val_loss: 0.0710 - val_accuracy: 0.9715\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 2.6214401285682084e-16.\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06993\n",
      "Epoch 74/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0617 - accuracy: 0.9757 - val_loss: 0.0755 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.06993\n",
      "Epoch 75/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0594 - accuracy: 0.9776 - val_loss: 0.0704 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06993\n",
      "Epoch 76/4000\n",
      "569/569 [==============================] - 49s 87ms/step - loss: 0.0623 - accuracy: 0.9752 - val_loss: 0.0704 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 5.2428803630155353e-17.\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.06993\n",
      "Epoch 77/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0635 - accuracy: 0.9757 - val_loss: 0.0703 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06993\n",
      "Epoch 78/4000\n",
      "569/569 [==============================] - 50s 87ms/step - loss: 0.0638 - accuracy: 0.9766 - val_loss: 0.0704 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06993\n",
      "Epoch 00078: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=BATCH_SIZE, epochs=4000,\n",
    "                    # validation_steps=int(np.ceil(X_val.shape[0]/BATCH_SIZE)), \n",
    "                    # callbacks=[rlr_cb, checkpoint]\n",
    "                    callbacks=[rlr_cb, ely_cb, checkpoint]\n",
    "                   )\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-guatemala",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "error",
     "timestamp": 1623219285223,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "lesbian-guatemala",
    "outputId": "dd2b65eb-ce9c-4093-b4d4-3e1c799b6e38"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ff7c22e98d80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'go', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-location",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18276,
     "status": "ok",
     "timestamp": 1622907522784,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "demographic-location",
    "outputId": "06d29d95-d196-4621-a17c-15ae04488272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 17s 65ms/step - loss: 0.0654 - accuracy: 0.9700\n",
      "정확도 : 0.97 \n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('/content/COVIDMD.h5')\n",
    "print(\"정확도 : %.2f \" %(model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-temperature",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4754,
     "status": "ok",
     "timestamp": 1623219412742,
     "user": {
      "displayName": "김수은",
      "photoUrl": "",
      "userId": "14383167240668166265"
     },
     "user_tz": -540
    },
    "id": "collaborative-temperature",
    "outputId": "ed7ba451-1347-479f-dd6d-4a2ab467de63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative_1.png : , Predict : COVID\n",
      "Positive_2.png : , Predict : COVID\n",
      "Positive_1.png : , Predict : Non-COVID\n",
      "Negative_2.png : , Predict : COVID\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "from numpy import argmax\n",
    "from keras.models import load_model\n",
    "\n",
    "image_dir = '/content/drive/MyDrive/Covid Model/test/'\n",
    "categories = ['COVID','Non-COVID']\n",
    "\n",
    "def Dataization(img_path):\n",
    "    image_w = 112\n",
    "    image_h = 112\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, None, fx=image_w/img.shape[1], fy=image_h/img.shape[0])\n",
    "    return (img/256)\n",
    " \n",
    "src = []\n",
    "name = []\n",
    "test = []\n",
    "\n",
    "for file in os.listdir(image_dir):\n",
    "    if (file.find('.png') is not -1):      \n",
    "        src.append(image_dir + file)\n",
    "        name.append(file)\n",
    "        test.append(Dataization(image_dir + file))\n",
    " \n",
    " \n",
    "test = np.array(test)\n",
    "model = load_model('/content/drive/MyDrive/Covid Model/COVIDMD.h5')\n",
    "predict = model.predict_classes(test)\n",
    " \n",
    "for i in range(len(test)):\n",
    "    print(name[i] + \" : , Predict : \"+ str(categories[predict[i]]))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "notebook8f7ef5641f.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2959.231514,
   "end_time": "2021-06-03T07:07:54.892900",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-03T06:18:35.661386",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
